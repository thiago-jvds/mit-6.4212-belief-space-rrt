simulation:
  light_center: [ -0.5, 0.75, 0.5 ]
  light_size: [ 0.25, 0.25, 0.25 ]
  q_home: [ 0, 0.1, 0, -1.2, 0, 1.6, 0 ]
  q_goal: [ 0.0, 0.709, 0.0, -1.601, 0.0, -0.739, 0.0 ]

physics:
  # Process Noise is ZERO. 
  # The target does not move/drift. The robot moves perfectly.
  process_noise_scale: 0.0

  # Sensor Noise:
  # Light: High precision (info gain). Dark: Blind.
  meas_noise_light: 0.01
  meas_noise_dark: 1e+9

  # Keep buffer to avoid hitting the bottle while exploring
  safety_buffer_radius: 0.08

planner:
  max_iterations: 10000

  # INITIAL BELIEF: We start knowing very little about the target.
  # Trace(Sigma) = 7.0 (High uncertainty)
  initial_target_uncertainty: 1.0

  # GOAL CONDITION: We cannot finish unless we are confident.
  # Threshold to attempt the grasp.
  max_uncertainty: 0.01

  # COST FUNCTION: cost = path_length + lambda_weight × trace(Σ)
  # - Small lambda (0.1-1): Prioritize shorter paths
  # - Medium lambda (1-10): Balanced
  # - Large lambda (100+): Prioritize uncertainty reduction (old behavior)
  lambda_weight: 0.1

  # Biases
  prob_sample_goal: 0.5
  prob_sample_light: 0.5
  q_light_hint: [ 0.663, 0.746, 0.514, -1.406, 0.996, -1.306, -1.028 ]
